# Containers

- **Containers** are a form of virtualization that allow you to run applications in an isolated environment.
- They bundle together the application, the operating system (OS) dependencies, and the runtime environment into a single package.
- Containers run on top of a host operating system, similar to virtual machines (VMs), but they do not require a separate OS for each container.
  - Unlike VMs, containers do not use hardware virtualization.
  - Containers package the necessary libraries and components for the application to run, leveraging the host OS directly.
    - This avoids the overhead of simulating virtual hardware and running multiple redundant operating systems.
    - This means you can run many isolated applications on a single host, using fewer resources compared to VMs.
    - This efficiency allows for quicker adjustments to changing demand or failures.
    - For example, if five containers are running on a server with a specific Linux kernel, all five containers share that same kernel.
- A **container orchestrator** can manage container instances by starting, stopping, and scaling them as needed.
  - This orchestration is much faster than with VMs, taking seconds instead of minutes.
- Containers allow multiple applications to be hosted on the same server.
  - They provide security and isolation between applications.
- Containers are more efficient than VMs because:
  - They run side by side without compromising isolation.
  - They are much smaller in size.
  - The development process is simplified, as the development environment matches the production environment.

## Containers in Azure

### Azure Container Instances

- **Azure Container Instances** is a Platform-as-a-Service (PaaS) solution that provides the fastest and simplest way to run containers.
- With Azure Container Instances, you do not need to configure virtual machines or additional services.
- You can simply upload your containers and run them, with automatic scaling included.

### Azure Kubernetes Service

- **Azure Kubernetes Service (AKS)** handles container orchestration, which involves automating, managing, and interacting with many containers.
- AKS is a comprehensive service for orchestrating containers.
- You can migrate existing applications to AKS by following these steps:
  1. Convert your application into one or more containers and publish these container images to the Azure Container Registry.
  2. Deploy these containers to an AKS cluster using either the Azure portal or command line tools.
  3. Azure Active Directory (AD) manages access to AKS resources.
  4. You can access Azure services with Service Level Agreement (SLA) backing, such as Azure Database for MySQL, through the Open Service Broker API (OSBA).
  5. Optionally, you can deploy AKS within a virtual network.

#### Kubernetes

- **Kubernetes** is a widely used platform for managing containerized workloads.
- It combines automation of container management with an API for control and interaction.
- Kubernetes is cloud-native and can operate across different cloud providers.
- **Pod Management:**
  - A **pod** is a group of one or more containers that share the same network namespace, allowing them to communicate with each other via 'localhost'.
  - Each pod runs on a node, and if a node fails, Kubernetes will move the affected workloads to another node.
  - If a pod crashes, Kubernetes will create a new instance of it.
  - Pods can be scaled manually or automatically (horizontally).
- Kubernetes ensures minimal downtime during deployments by spreading out updates and rolling back if necessary.
- **Storage Management:**
  - Kubernetes can manage persistent volumes, which represent data storage that persists beyond the lifecycle of a single pod.
  - It supports cloud-based storage solutions like Azure Storage and Cosmos DB.
- **Networking Management:**
  - Kubernetes can expose pods to the internet and load-balance traffic across multiple pod replicas.
  - It provides network isolation and policy-driven security.
  - It manages communication and name resolution between pods.
- Kubernetes can be extended with additional features, such as cloud event notifications on pod creation, custom pod scheduling logic, and on-demand provisioning of managed cloud services.

## Micro-services

- **Micro-services** is an architectural style that breaks down applications into smaller, independent services.
- This architecture allows you to divide your application into distinct sections, which can be maintained, scaled, and updated independently.
- Each micro-service has a small codebase that can be managed by a small development team.
- Micro-services do not need to share the same technology stack, libraries, or frameworks.
  - Each team can choose the tools and technologies that best fit their needs.
  - This enables individual teams to test, build, and deploy their services independently.
- This approach promotes continuous innovation and faster release cycles.
- Smaller codebases:
  - Make it easier to understand and manage.
  - Help new team members get up to speed more quickly.
- Each micro-service operates independently without cross-dependencies.
  - This design provides fault isolation, so if one service fails, it does not impact the entire application.
- Micro-services communicate with each other using Application Programming Interfaces (APIs).
  - APIs encapsulate the internal functionality of each service.
    - The internal details are hidden behind the API interface.
  - **Best Practices:**
    - Minimize interdependencies between services.
    - Use an orchestration or management layer in the higher-level application to coordinate calls and aggregate results.
- **Ideal For:**
  - Applications requiring frequent updates and high release velocity.
  - Applications that need to be highly scalable.
  - Applications with complex domains or subdomains.
  - Organizations with small, specialized development teams.

### Micro-services Deployment

- Micro-services can be deployed independently of each other.
- Teams can update and deploy individual services without needing to rebuild or redeploy the entire application.
- This allows for easier rollbacks and forward updates if issues arise.
- It simplifies bug fixes and feature releases, making them less risky and more manageable.
- Each micro-service:
  - Can be scaled independently of others.
  - Manages its own data and state without relying on a common repository layer.
- For example, you could have separate micro-services for the front-end, back-end, and storage.
  - If the back-end service reaches capacity but the other services do not, you can scale the back-end service individually.
  - This separation allows you to replace or upgrade the storage service without affecting the rest of the application.

### Azure Service Fabric

- **Azure Service Fabric** is a distributed systems platform that supports the deployment and management of micro-services.
- It can run in Azure or on-premises, providing flexibility for various deployment scenarios.
